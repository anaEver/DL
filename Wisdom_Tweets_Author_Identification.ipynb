{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wisdom_Tweets_Author_Identification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOr34s2u54D0M+aljH+Mgp+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anaEver/DL/blob/main/Wisdom_Tweets_Author_Identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrRB0mZS6EnF"
      },
      "source": [
        "# Data Preperation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhFuoAXtioDh",
        "outputId": "9a6b44d6-0726-4085-8e8b-8872d6bb39ac"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import nltk\r\n",
        "import io\r\n",
        "import zipfile\r\n",
        "from sklearn import preprocessing\r\n",
        "!pip install emoji --upgrade\r\n",
        "#nltk.download('stopwords')\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "from tqdm import tqdm\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers.recurrent import LSTM, GRU\r\n",
        "from keras.layers.core import Dense, Activation, Dropout\r\n",
        "from keras.layers.embeddings import Embedding\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras.utils import np_utils\r\n",
        "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from keras.preprocessing import sequence\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.callbacks import EarlyStopping\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from google.colab import files\r\n",
        "from nltk.corpus import stopwords\r\n",
        "\r\n",
        "#stop_words = stopwords.words('english')\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/1c/1f1457fe52d0b30cbeebfd578483cedb3e3619108d2d5a21380dfecf8ffd/emoji-0.6.0.tar.gz (51kB)\n",
            "\r\u001b[K     |██████▍                         | 10kB 17.1MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 20kB 23.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 30kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 40kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.6.0-cp36-none-any.whl size=49717 sha256=5f085c929cb3cdf64166c86d8b54661c9009f84ed891b3215075ea2d737f9fa2\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/2c/8b/9dcf5216ca68e14e0320e283692dce8ae321cdc01e73e17796\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.6.0\n",
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi3jZgjYDjhm",
        "outputId": "cc95a1b4-da63-4825-d655-403389c047ba"
      },
      "source": [
        "url = 'https://github.com/Hsankesara/The-Tweets-of-Wisdom/raw/master/tweets.csv'\r\n",
        "#url = 'https://github.com/anaEver/DL/blob/main/export_dataframe.csv'\r\n",
        "df = pd.read_csv(url)\r\n",
        "df.tweet_content.size"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31115"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "8CSt6bgzjrA5",
        "outputId": "b3b27a58-a815-4d5e-d6ae-8b97a291996d"
      },
      "source": [
        "df['tweet_content']=df['tweet_content'].str.lower()\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author_name</th>\n",
              "      <th>created_at</th>\n",
              "      <th>handle</th>\n",
              "      <th>likes</th>\n",
              "      <th>retweets</th>\n",
              "      <th>tweet_content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Naval</td>\n",
              "      <td>2019-08-07 22:36:56</td>\n",
              "      <td>naval</td>\n",
              "      <td>7566</td>\n",
              "      <td>1498</td>\n",
              "      <td>unresolved thoughts, prematurely pushed out of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Naval</td>\n",
              "      <td>2019-08-07 05:00:38</td>\n",
              "      <td>naval</td>\n",
              "      <td>21886</td>\n",
              "      <td>5984</td>\n",
              "      <td>the modern mind is overstimulated and the mode...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Naval</td>\n",
              "      <td>2019-08-07 04:52:33</td>\n",
              "      <td>naval</td>\n",
              "      <td>6462</td>\n",
              "      <td>1266</td>\n",
              "      <td>the lindy effect for startups:\\n\\nthe longer y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Naval</td>\n",
              "      <td>2019-08-06 08:35:26</td>\n",
              "      <td>naval</td>\n",
              "      <td>466</td>\n",
              "      <td>61</td>\n",
              "      <td>@orangebook_ this was a good tweet.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Naval</td>\n",
              "      <td>2019-08-06 07:33:20</td>\n",
              "      <td>naval</td>\n",
              "      <td>3971</td>\n",
              "      <td>906</td>\n",
              "      <td>social media lowers the cost of raising &amp;amp; ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  author_name  ...                                      tweet_content\n",
              "0       Naval  ...  unresolved thoughts, prematurely pushed out of...\n",
              "1       Naval  ...  the modern mind is overstimulated and the mode...\n",
              "2       Naval  ...  the lindy effect for startups:\\n\\nthe longer y...\n",
              "3       Naval  ...               @orangebook_ this was a good tweet. \n",
              "4       Naval  ...  social media lowers the cost of raising &amp; ...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87jvYJ15Lf1k",
        "outputId": "f29a85d6-3bac-4daf-f65a-e4faf45210e5"
      },
      "source": [
        "import math\r\n",
        "i = 0\r\n",
        "\r\n",
        "for x in df.author_name.unique():\r\n",
        "  if isinstance(x , str):\r\n",
        "    \r\n",
        "    y = df.loc[df['author_name'] == x, 'handle']\r\n",
        "    #print(y.unique())\r\n",
        "    if y.nunique()>1:\r\n",
        "      print(\"*****************author:\"+x)\r\n",
        "      df.loc[df['author_name'] == x, 'handle'] = x\r\n",
        "      print(\"handles: {}\".format(y.nunique()))\r\n",
        "      i = i + 1\r\n",
        "\r\n",
        "for x in df.author_name:\r\n",
        "  if isinstance(x , str):   \r\n",
        "    i = i + 1\r\n",
        "  elif math.isnan(x):\r\n",
        "    print(x)\r\n",
        "    df.loc[i, 'author_name'] = 'undefined'\r\n",
        "    i = i + 1\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqvR96y9OdhB",
        "outputId": "a842c954-5501-4e57-82d6-8d76918733b6"
      },
      "source": [
        "import emoji\r\n",
        "i = 0\r\n",
        "for x in df.author_name:\r\n",
        "  if isinstance(x, str):\r\n",
        "    y = emoji.demojize(x)\r\n",
        "  elif math.isnan(x):\r\n",
        "    y = 'undefined'\r\n",
        "  df.loc[i, 'author_name'] = y\r\n",
        "  i = i + 1\r\n",
        "print(df.handle.nunique())\r\n",
        "print(df.author_name.nunique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2782\n",
            "2782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVRtKW6JQaCA",
        "outputId": "b775ebbf-ad4d-4c82-b6e6-865e784cb220"
      },
      "source": [
        "df.to_csv (r'./tweets.csv', index = False, header=True)\r\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;32manscombe.json\u001b[0m*                mnist_test.csv         tweets.csv\n",
            "california_housing_test.csv   mnist_train_small.csv\n",
            "california_housing_train.csv  \u001b[01;32mREADME.md\u001b[0m*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2XMQlsNSEBm",
        "outputId": "3064e4b2-6ea7-4ddb-c0e7-20caf1d62043"
      },
      "source": [
        "label_encoder = preprocessing.LabelEncoder()\r\n",
        "labels = label_encoder.fit_transform(df.handle.values)\r\n",
        "np.unique(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    1,    2, ..., 2779, 2780, 2781])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gySwZLZlOztd"
      },
      "source": [
        "df.tweet_content  = df.tweet_content.astype(str)\r\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(df.tweet_content.values, labels, \r\n",
        "  \r\n",
        " random_state=42, \r\n",
        " test_size=0.2, shuffle=True)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKcvKiQVFRB4"
      },
      "source": [
        "# GloVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imLJrp1XFXxS",
        "outputId": "32e765f5-83cf-4457-9ef9-8405fcb341ea"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.twitter.27B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-10 11:39:35--  http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.twitter.27B.zip [following]\n",
            "--2021-01-10 11:39:35--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip [following]\n",
            "--2021-01-10 11:39:35--  http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1520408563 (1.4G) [application/zip]\n",
            "Saving to: ‘glove.twitter.27B.zip’\n",
            "\n",
            "glove.twitter.27B.z 100%[===================>]   1.42G  2.03MB/s    in 11m 41s \n",
            "\n",
            "2021-01-10 11:51:16 (2.07 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-_lWixQJIY1",
        "outputId": "f366f3fa-65f2-4b7b-c639-9a243c67b563"
      },
      "source": [
        "!unzip glove.twitter.27B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.twitter.27B.zip\n",
            "  inflating: glove.twitter.27B.25d.txt  \n",
            "  inflating: glove.twitter.27B.50d.txt  \n",
            "  inflating: glove.twitter.27B.100d.txt  \n",
            "  inflating: glove.twitter.27B.200d.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHQFPuxDJdTY",
        "outputId": "f75ba9e6-3ab4-4e4f-b14b-7c39c35cb0b0"
      },
      "source": [
        "!ls\r\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "anscombe.json\t\t      glove.twitter.27B.200d.txt  mnist_test.csv\n",
            "california_housing_test.csv   glove.twitter.27B.25d.txt   mnist_train_small.csv\n",
            "california_housing_train.csv  glove.twitter.27B.50d.txt   README.md\n",
            "glove.twitter.27B.100d.txt    glove.twitter.27B.zip\t  tweets.csv\n",
            "/content/sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEhktqpyJh7p",
        "outputId": "510994a9-11fb-424b-8fdf-28de25135b86"
      },
      "source": [
        "print('Indexing word vectors.')\r\n",
        "\r\n",
        "embeddings_index_100 = {}\r\n",
        "f = open('glove.twitter.27B.100d.txt', encoding='utf-8')\r\n",
        "for line in f:\r\n",
        "    values = line.split()\r\n",
        "    word = values[0]\r\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\r\n",
        "    embeddings_index_100[word] = coefs\r\n",
        "f.close()\r\n",
        "\r\n",
        "print('Found %s word vectors.' % len(embeddings_index_100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Indexing word vectors.\n",
            "Found 1193514 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n2PjJ9rKFeg",
        "outputId": "59c9e356-4e07-47be-ffb5-f08e1f2094bb"
      },
      "source": [
        "!pip install --upgrade pip\r\n",
        "!pip install -U -q pydrive\r\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\r\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\r\n",
        "!apt-get update -qq 2>&1 > /dev/null\r\n",
        "\r\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\r\n",
        "\r\n",
        "from google.colab import auth\r\n",
        "auth.authenticate_user()\r\n",
        "# Generate creds for the Drive FUSE library.\r\n",
        "from oauth2client.client import GoogleCredentials\r\n",
        "creds = GoogleCredentials.get_application_default()\r\n",
        "import getpass\r\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\r\n",
        "vcode = getpass.getpass()\r\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\r\n",
        "\r\n",
        "!mkdir -p drive\r\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (20.3.3)\n",
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxzrygsmK-NN"
      },
      "source": [
        "import pickle\r\n",
        "pickle.dump({'embeddings_index_100' : embeddings_index_100 } , open('drive/glove_100', 'wb'))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltVWjPYEMxNd",
        "outputId": "aeccfb3b-b8f5-44f1-ef67-8a02ef6615b4"
      },
      "source": [
        "print('Indexing word vectors.')\r\n",
        "\r\n",
        "embeddings_index_50 = {}\r\n",
        "f = open('glove.twitter.27B.50d.txt', encoding='utf-8')\r\n",
        "for line in f:\r\n",
        "    values = line.split()\r\n",
        "    word = values[0]\r\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\r\n",
        "    embeddings_index_50[word] = coefs\r\n",
        "f.close()\r\n",
        "\r\n",
        "print('Found %s word vectors.' % len(embeddings_index_50))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Indexing word vectors.\n",
            "Found 1193514 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElnKgTT8NM3X"
      },
      "source": [
        "import pickle\r\n",
        "pickle.dump({'embeddings_index_50' : embeddings_index_50 } , open('drive/glove_50', 'wb'))"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeQbTmVhP9XY"
      },
      "source": [
        "VOCABULARY_SIZE = 2000\r\n",
        "MAX_LENGTH = 60\r\n",
        "\r\n",
        "tokenizer = Tokenizer(num_words=VOCABULARY_SIZE)\r\n",
        "tokenizer.fit_on_texts(list(xtrain) + list(xtest))"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQgnrTePTmmb"
      },
      "source": [
        "xtrain_sequence = tokenizer.texts_to_sequences(xtrain)\r\n",
        "xtest_sequence = tokenizer.texts_to_sequences(xtest)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2D7K8-JVT2i"
      },
      "source": [
        "xtrain_padding = sequence.pad_sequences(xtrain_sequence, maxlen=MAX_LENGTH)\r\n",
        "xtest_padding = sequence.pad_sequences(xtest_sequence, maxlen=MAX_LENGTH)\r\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cs_76uuGVXdm",
        "outputId": "0032e463-9e5b-44a4-8005-3ba4edc0140c"
      },
      "source": [
        "embedding_matrix = np.zeros((len(word_index) + 1, 100))\r\n",
        "for word, i in tqdm(word_index.items()):\r\n",
        "  embedding_vector = embeddings_index_100.get(word)\r\n",
        "  if embedding_vector is not None:\r\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 37226/37226 [00:00<00:00, 475277.34it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0pzbWo7Voq2"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX-50k8yVr8V"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Embedding(len(word_index) + 1,\r\n",
        " 100,\r\n",
        " weights=[embedding_matrix],\r\n",
        " input_length=MAX_LENGTH,\r\n",
        " trainable=False))\r\n",
        "model.add(SpatialDropout1D(0.3))\r\n",
        "model.add(Bidirectional(LSTM(50, dropout=0.3, recurrent_dropout=0.3)))\r\n",
        "model.add(Dense(1024, activation='relu'))\r\n",
        "model.add(Dropout(0.8))\r\n",
        "model.add(Dense(1024, activation='relu'))\r\n",
        "model.add(Dropout(0.8))\r\n",
        "model.add(Dense(2782))\r\n",
        "model.add(Activation('softmax'))\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp9gTfQ1V74x"
      },
      "source": [
        "ytrain_encode = np_utils.to_categorical(ytrain, 2782)\r\n",
        "ytest_encode = np_utils.to_categorical(ytest, 2782)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfTCSyBnV-O_",
        "outputId": "d8f00e95-7919-449c-a741-707a858cd1ce"
      },
      "source": [
        "\r\n",
        "history = model.fit(xtrain_padding, y=ytrain_encode, batch_size=512, epochs=40, verbose=1, validation_data=(xtest_padding, ytest_encode))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "49/49 [==============================] - 49s 997ms/step - loss: 3.6780 - accuracy: 0.2234 - val_loss: 4.2246 - val_accuracy: 0.2439\n",
            "Epoch 2/40\n",
            "49/49 [==============================] - 48s 984ms/step - loss: 3.6815 - accuracy: 0.2237 - val_loss: 4.2316 - val_accuracy: 0.2462\n",
            "Epoch 3/40\n",
            "49/49 [==============================] - 48s 988ms/step - loss: 3.6614 - accuracy: 0.2274 - val_loss: 4.2294 - val_accuracy: 0.2433\n",
            "Epoch 4/40\n",
            "49/49 [==============================] - 48s 985ms/step - loss: 3.6631 - accuracy: 0.2272 - val_loss: 4.2270 - val_accuracy: 0.2470\n",
            "Epoch 5/40\n",
            "49/49 [==============================] - 48s 980ms/step - loss: 3.6532 - accuracy: 0.2284 - val_loss: 4.2454 - val_accuracy: 0.2446\n",
            "Epoch 6/40\n",
            "49/49 [==============================] - 48s 978ms/step - loss: 3.6470 - accuracy: 0.2259 - val_loss: 4.2465 - val_accuracy: 0.2452\n",
            "Epoch 7/40\n",
            "49/49 [==============================] - 48s 983ms/step - loss: 3.6481 - accuracy: 0.2289 - val_loss: 4.2476 - val_accuracy: 0.2457\n",
            "Epoch 8/40\n",
            "49/49 [==============================] - 48s 978ms/step - loss: 3.6351 - accuracy: 0.2264 - val_loss: 4.2482 - val_accuracy: 0.2484\n",
            "Epoch 9/40\n",
            "49/49 [==============================] - 48s 979ms/step - loss: 3.6244 - accuracy: 0.2273 - val_loss: 4.2644 - val_accuracy: 0.2465\n",
            "Epoch 10/40\n",
            "49/49 [==============================] - 48s 981ms/step - loss: 3.6136 - accuracy: 0.2303 - val_loss: 4.2493 - val_accuracy: 0.2455\n",
            "Epoch 11/40\n",
            "49/49 [==============================] - 48s 983ms/step - loss: 3.6106 - accuracy: 0.2295 - val_loss: 4.2584 - val_accuracy: 0.2475\n",
            "Epoch 12/40\n",
            "49/49 [==============================] - 48s 980ms/step - loss: 3.6001 - accuracy: 0.2279 - val_loss: 4.2730 - val_accuracy: 0.2475\n",
            "Epoch 13/40\n",
            "49/49 [==============================] - 48s 977ms/step - loss: 3.5874 - accuracy: 0.2288 - val_loss: 4.2646 - val_accuracy: 0.2471\n",
            "Epoch 14/40\n",
            "49/49 [==============================] - 49s 991ms/step - loss: 3.5850 - accuracy: 0.2336 - val_loss: 4.2731 - val_accuracy: 0.2444\n",
            "Epoch 15/40\n",
            "49/49 [==============================] - 48s 981ms/step - loss: 3.5903 - accuracy: 0.2326 - val_loss: 4.2845 - val_accuracy: 0.2507\n",
            "Epoch 16/40\n",
            "49/49 [==============================] - 48s 985ms/step - loss: 3.5855 - accuracy: 0.2309 - val_loss: 4.2697 - val_accuracy: 0.2521\n",
            "Epoch 17/40\n",
            "49/49 [==============================] - 48s 981ms/step - loss: 3.5831 - accuracy: 0.2330 - val_loss: 4.3091 - val_accuracy: 0.2513\n",
            "Epoch 18/40\n",
            "49/49 [==============================] - 48s 984ms/step - loss: 3.5733 - accuracy: 0.2348 - val_loss: 4.2789 - val_accuracy: 0.2526\n",
            "Epoch 19/40\n",
            "49/49 [==============================] - 48s 983ms/step - loss: 3.5687 - accuracy: 0.2309 - val_loss: 4.2744 - val_accuracy: 0.2520\n",
            "Epoch 20/40\n",
            "49/49 [==============================] - 48s 988ms/step - loss: 3.5654 - accuracy: 0.2358 - val_loss: 4.2965 - val_accuracy: 0.2512\n",
            "Epoch 21/40\n",
            "49/49 [==============================] - 48s 984ms/step - loss: 3.5572 - accuracy: 0.2339 - val_loss: 4.2991 - val_accuracy: 0.2508\n",
            "Epoch 22/40\n",
            "49/49 [==============================] - 48s 983ms/step - loss: 3.5490 - accuracy: 0.2333 - val_loss: 4.3069 - val_accuracy: 0.2510\n",
            "Epoch 23/40\n",
            "49/49 [==============================] - 48s 985ms/step - loss: 3.5481 - accuracy: 0.2332 - val_loss: 4.3025 - val_accuracy: 0.2513\n",
            "Epoch 24/40\n",
            "49/49 [==============================] - 48s 980ms/step - loss: 3.5352 - accuracy: 0.2343 - val_loss: 4.3056 - val_accuracy: 0.2504\n",
            "Epoch 25/40\n",
            "49/49 [==============================] - 48s 985ms/step - loss: 3.5368 - accuracy: 0.2367 - val_loss: 4.3261 - val_accuracy: 0.2526\n",
            "Epoch 26/40\n",
            "49/49 [==============================] - 48s 981ms/step - loss: 3.5297 - accuracy: 0.2366 - val_loss: 4.3201 - val_accuracy: 0.2528\n",
            "Epoch 27/40\n",
            "49/49 [==============================] - 48s 991ms/step - loss: 3.5337 - accuracy: 0.2351 - val_loss: 4.3102 - val_accuracy: 0.2542\n",
            "Epoch 28/40\n",
            "49/49 [==============================] - 48s 982ms/step - loss: 3.5249 - accuracy: 0.2370 - val_loss: 4.3271 - val_accuracy: 0.2537\n",
            "Epoch 29/40\n",
            "49/49 [==============================] - 48s 983ms/step - loss: 3.5158 - accuracy: 0.2379 - val_loss: 4.3121 - val_accuracy: 0.2526\n",
            "Epoch 30/40\n",
            "49/49 [==============================] - 48s 985ms/step - loss: 3.5143 - accuracy: 0.2359 - val_loss: 4.3374 - val_accuracy: 0.2529\n",
            "Epoch 31/40\n",
            "49/49 [==============================] - 48s 980ms/step - loss: 3.5012 - accuracy: 0.2395 - val_loss: 4.3416 - val_accuracy: 0.2547\n",
            "Epoch 32/40\n",
            "49/49 [==============================] - 48s 979ms/step - loss: 3.5020 - accuracy: 0.2363 - val_loss: 4.3422 - val_accuracy: 0.2557\n",
            "Epoch 33/40\n",
            "49/49 [==============================] - 48s 989ms/step - loss: 3.4948 - accuracy: 0.2428 - val_loss: 4.3572 - val_accuracy: 0.2549\n",
            "Epoch 34/40\n",
            "49/49 [==============================] - 48s 982ms/step - loss: 3.4999 - accuracy: 0.2371 - val_loss: 4.3215 - val_accuracy: 0.2549\n",
            "Epoch 35/40\n",
            "49/49 [==============================] - 48s 987ms/step - loss: 3.4834 - accuracy: 0.2383 - val_loss: 4.3444 - val_accuracy: 0.2553\n",
            "Epoch 36/40\n",
            "49/49 [==============================] - 48s 986ms/step - loss: 3.4868 - accuracy: 0.2373 - val_loss: 4.3535 - val_accuracy: 0.2566\n",
            "Epoch 37/40\n",
            "49/49 [==============================] - 48s 986ms/step - loss: 3.4654 - accuracy: 0.2423 - val_loss: 4.3566 - val_accuracy: 0.2611\n",
            "Epoch 38/40\n",
            "49/49 [==============================] - 48s 987ms/step - loss: 3.4695 - accuracy: 0.2393 - val_loss: 4.3580 - val_accuracy: 0.2579\n",
            "Epoch 39/40\n",
            "49/49 [==============================] - 49s 995ms/step - loss: 3.4647 - accuracy: 0.2410 - val_loss: 4.3649 - val_accuracy: 0.2608\n",
            "Epoch 40/40\n",
            "49/49 [==============================] - 49s 997ms/step - loss: 3.4721 - accuracy: 0.2420 - val_loss: 4.3843 - val_accuracy: 0.2523\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}